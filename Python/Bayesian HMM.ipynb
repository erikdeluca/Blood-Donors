{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Bayesian HMM\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Import and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "import matplotlib.pyplot as plt\n",
        "from pyprojroot import here\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.distributions.constraints as constraints\n",
        "from pyro.infer import SVI, TraceEnum_ELBO\n",
        "from pyro.optim import Adam\n",
        "from scipy.stats import poisson\n",
        "import torch\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv(here(\"data/recent_donations.csv\"))\n",
        "data\n",
        "\n",
        "# remove columns y_2020 to y_2023\n",
        "# data = data.drop(columns=[\"y_2020\", \"y_2021\", \"y_2022\", \"y_2023\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Required libraries\n",
        "# ------------------------------------------------------------------\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. Load data into a Polars DataFrame\n",
        "# ------------------------------------------------------------------\n",
        "# df = pl.read_csv(\"file.csv\")          # Uncomment if reading from file\n",
        "df = pl.from_pandas(data)               # Convert from pandas if already in memory\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. Collect year columns and build the observation matrix [N, T]\n",
        "# ------------------------------------------------------------------\n",
        "year_cols = sorted([c for c in df.columns if c.startswith(\"y_\")])\n",
        "T = len(year_cols)\n",
        "\n",
        "obs = (\n",
        "    df.select(year_cols)                # Select y_* columns\n",
        "      .fill_null(0)                     # Replace NaNs by 0\n",
        "      .to_numpy()\n",
        "      .astype(int)                      # Ensure integer type\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3. Create fixed covariates per individual\n",
        "# ------------------------------------------------------------------\n",
        "df = df.with_columns(\n",
        "    [\n",
        "        (pl.col(\"gender\") == \"F\").cast(pl.Int8).alias(\"gender_code\"),      # 0 = M, 1 = F\n",
        "        (\n",
        "            (pl.col(\"birth_year\") - pl.col(\"birth_year\").mean()) /\n",
        "            pl.col(\"birth_year\").std()\n",
        "        ).alias(\"birth_year_norm\")                                         # Standardised birth year\n",
        "    ]\n",
        ")\n",
        "\n",
        "birth_year_norm = df[\"birth_year_norm\"].to_numpy()    # Shape [N]\n",
        "gender_code     = df[\"gender_code\"].to_numpy()        # Shape [N]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 4. Build dynamic covariates (age and COVID dummy)\n",
        "# ------------------------------------------------------------------\n",
        "years_num = np.array([int(c[2:]) for c in year_cols])                 # e.g. [2009, …, 2023]\n",
        "ages      = years_num[None, :] - df[\"birth_year\"].to_numpy()[:, None] # Shape [N, T]\n",
        "ages_norm = (ages - ages.mean()) / ages.std()                         # Standardised age\n",
        "\n",
        "covid_years = np.isin(years_num, [2020, 2021, 2022]).astype(float)    # Shape [T]\n",
        "covid_years = np.tile(covid_years, (df.height, 1))                    # Shape [N, T]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 5. Assemble the full covariate tensor [N, T, 5]\n",
        "#    Order: birth_year_norm, gender_code, ages_norm, covid_years, const\n",
        "# ------------------------------------------------------------------\n",
        "base_cov  = np.stack([birth_year_norm, gender_code], axis=1)          # Shape [N, 2]\n",
        "base_cov  = np.repeat(base_cov[:, None, :], T, axis=1)                # [N, T, 2]\n",
        "\n",
        "dyn_cov   = np.stack([ages_norm, covid_years], axis=2)                # [N, T, 2]\n",
        "\n",
        "const_cov = np.ones((df.height, T, 1), dtype=np.float32)              # Constant term\n",
        "\n",
        "full_cov  = np.concatenate([base_cov, dyn_cov, const_cov], axis=2)    # [N, T, 5]\n",
        "cov_names = [\"birth_year_norm\",\n",
        "             \"gender_code\",\n",
        "             \"ages_norm\",\n",
        "             \"covid_years\",\n",
        "             \"const\"]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 6. Convert to PyTorch tensors (optional)\n",
        "# ------------------------------------------------------------------\n",
        "obs_torch      = torch.tensor(obs,      dtype=torch.long)\n",
        "full_cov_torch = torch.tensor(full_cov, dtype=torch.float)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 7. Quick sanity check\n",
        "# ------------------------------------------------------------------\n",
        "print(\"obs       :\", obs.shape)        # (N, T)\n",
        "print(\"covariates:\", full_cov.shape)   # (N, T, 5)\n",
        "print(\"order     :\", cov_names)        # Confirm column order"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model\n",
        "\n",
        "-   3-state Poisson Hidden Markov Model.\n",
        "\n",
        "    $$\\pi \\sim \\text{Dirichlet}(\\mathbf 1)$$\\\n",
        "    $$A_{k\\cdot} \\sim \\text{Dirichlet}(\\mathbf 1)\\quad\\forall k$$\\\n",
        "    $$z_0 \\sim \\text{Categorical}(\\pi),\\qquad \n",
        "      z_t\\mid z_{t-1}\\sim\\text{Categorical}(A_{z_{t-1}\\cdot})$$\\\n",
        "    $$\\lambda_k \\sim \\text{Gamma}(2,1)$$\\\n",
        "    $$y_t \\mid z_t=k \\sim \\text{Poisson}(\\lambda_k)$$\n",
        "\n",
        "    Discrete chains $z_{n,t}$ are marginalised exactly via enumeration.\n",
        "\n",
        "Guide (mean-field)\\\n",
        "$$q(\\pi)=\\text{Dirichlet}(\\boldsymbol{\\alpha}_\\pi),\\qquad \n",
        "    q(A_{k\\cdot})=\\text{Dirichlet}(\\boldsymbol{\\alpha}_{A_k}),\\qquad\n",
        "    q(\\lambda_k)=\\text{Gamma}(\\alpha_k,\\beta_k)$$\n",
        "\n",
        "Hence $$q(\\pi,A,\\lambda)=q(\\pi)\\prod_k q(A_{k\\cdot})q(\\lambda_k)$$ with no cross-covariances; $z$’s remain exact.\n",
        "\n",
        "Training\\\n",
        "- Stochastic Variational Inference, Adam (lr = 0.05).\\\n",
        "- Objective: TraceEnum_ELBO(max_plate_nesting = 1).\\\n",
        "- ELBO descends from ≈174 k to ≈130 k; posterior means $\\hat\\pi$, $\\hat A$, $\\hat\\lambda$ are reported together with their Dirichlet/Gamma uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "K = 3              # n. stati latenti\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  MODEL                                                             #\n",
        "# ------------------------------------------------------------------ #\n",
        "def model(obs):\n",
        "    N, T = obs.shape\n",
        "\n",
        "    # π   (prob. iniziali)  – una sola Dirichlet\n",
        "    pi = pyro.sample(\"pi\", dist.Dirichlet(torch.ones(K)))              # [K]\n",
        "\n",
        "    # A   (matrice di transizione)  – K Dirichlet, una per riga\n",
        "    with pyro.plate(\"row\", K):\n",
        "        A = pyro.sample(\"A\", dist.Dirichlet(torch.ones(K)))            # [K,K]\n",
        "\n",
        "    # tassi Poisson\n",
        "    rates = pyro.sample(\"rates\",\n",
        "                        dist.Gamma(2.*torch.ones(K),\n",
        "                                   1.*torch.ones(K)).to_event(1))      # [K]\n",
        "\n",
        "    # osservazioni\n",
        "    with pyro.plate(\"donor\", N):\n",
        "        z = pyro.sample(\"z_0\", dist.Categorical(pi),\n",
        "                        infer={\"enumerate\": \"parallel\"})\n",
        "\n",
        "        for t in pyro.markov(range(T)):\n",
        "            pyro.sample(f\"y_{t}\", dist.Poisson(rates[z]),\n",
        "                        obs=obs[:, t])\n",
        "            if t < T-1:\n",
        "                z = pyro.sample(f\"z_{t+1}\", dist.Categorical(A[z]),\n",
        "                                infer={\"enumerate\": \"parallel\"})\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  GUIDE                                                             #\n",
        "# ------------------------------------------------------------------ #\n",
        "def guide(obs):\n",
        "    # variational params\n",
        "    pi_alpha    = pyro.param(\"pi_alpha\",\n",
        "                             torch.ones(K),\n",
        "                             constraint=dist.constraints.positive)     # [K]\n",
        "\n",
        "    A_alpha     = pyro.param(\"A_alpha\",\n",
        "                             torch.ones(K, K),\n",
        "                             constraint=dist.constraints.positive)     # [K,K]\n",
        "\n",
        "    r_alpha     = pyro.param(\"r_alpha\",\n",
        "                             2.*torch.ones(K),\n",
        "                             constraint=dist.constraints.positive)     # [K]\n",
        "    r_beta      = pyro.param(\"r_beta\",\n",
        "                             1.*torch.ones(K),\n",
        "                             constraint=dist.constraints.positive)\n",
        "\n",
        "    pyro.sample(\"pi\", dist.Dirichlet(pi_alpha))\n",
        "\n",
        "    with pyro.plate(\"row\", K):\n",
        "        pyro.sample(\"A\", dist.Dirichlet(A_alpha))\n",
        "\n",
        "    pyro.sample(\"rates\", dist.Gamma(r_alpha, r_beta).to_event(1))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  TRAINING                                                          #\n",
        "# ------------------------------------------------------------------ #\n",
        "pyro.clear_param_store()\n",
        "svi = SVI(model, guide, Adam({\"lr\": 0.05}),\n",
        "          loss=TraceEnum_ELBO(max_plate_nesting=1))\n",
        "\n",
        "for step in range(1000):\n",
        "    loss = svi.step(obs_torch)\n",
        "    if step % 100 == 0:\n",
        "        print(f\"{step:4d}  ELBO = {loss:,.0f}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "#  PARAMETRI “MEAN” DOPO IL TRAINING                                 #\n",
        "# ------------------------------------------------------------------ #\n",
        "with torch.no_grad():\n",
        "    pi_mean = pyro.param(\"pi_alpha\")\n",
        "    pi_mean = pi_mean / pi_mean.sum()\n",
        "\n",
        "    A_alpha = pyro.param(\"A_alpha\")\n",
        "    A_mean  = A_alpha / A_alpha.sum(dim=1, keepdim=True)   # somma 1 per riga\n",
        "\n",
        "    rates   = pyro.param(\"r_alpha\") / pyro.param(\"r_beta\")\n",
        "\n",
        "print(\"\\nπ:\", pi_mean.numpy())\n",
        "print(\"\\nA (ogni riga somma a 1):\\n\", A_mean.numpy())\n",
        "print(\"\\nrates:\", rates.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "• ELBO steadily decreases from ≈174 k to ≈130 k and then plateaus → optimisation has mostly converged.\n",
        "\n",
        "• Initial-state distribution π – State 0 dominates (74 %), followed by state 1 (18 %); state 2 is rare (8 %). – Most donors start in state 0.\n",
        "\n",
        "• Transition matrix A – Strong self-persistence: P(0 → 0)=0.88, P(1 → 1)=0.98, P(2 → 2)=0.99. – Cross-state moves are all \\< 9 %; once a donor is in a state, they tend to stay there.\n",
        "\n",
        "• Poisson rates – State 0: λ≈0.006 (almost no donations) – State 1: λ≈2.42 (frequent donors) – State 2: λ≈0.83 (occasional donors)\n",
        "\n",
        "Interpretation: the model has discovered three very stable behavioural profiles—non-donors, heavy donors, and light donors—with rare transitions between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def plot_hmm_params(transitions, initial_probs, emissions,\n",
        "                    state_names=None, emission_names=None):\n",
        "    \"\"\"\n",
        "    Plotta in una riga:\n",
        "    - Matrice di transizione [S, S]\n",
        "    - Prob iniziali [S]\n",
        "    - Matrice emissioni [S, K]\n",
        "    \"\"\"\n",
        "    S = len(initial_probs)\n",
        "    K = emissions.shape[1]\n",
        "    if state_names is None:\n",
        "        state_names = [f\"State {i}\" for i in range(S)]\n",
        "    if emission_names is None:\n",
        "        emission_names = [str(i) for i in range(K)]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
        "\n",
        "    # Initial probabilities\n",
        "    axs[0].bar(np.arange(S), initial_probs, color='royalblue')\n",
        "    axs[0].set_title('Initial State Probabilities')\n",
        "    axs[0].set_xlabel('State')\n",
        "    axs[0].set_ylabel('Probability')\n",
        "    axs[0].set_xticks(np.arange(S))\n",
        "    axs[0].set_xticklabels(state_names)\n",
        "    axs[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Transition matrix\n",
        "    sns.heatmap(transitions, annot=True, fmt=\".2f\", cmap='Greens',\n",
        "                xticklabels=state_names, yticklabels=state_names, ax=axs[1], cbar=False)\n",
        "    axs[1].set_title('Transition Probabilities')\n",
        "    axs[1].set_xlabel('Next State')\n",
        "    axs[1].set_ylabel('Current State')\n",
        "\n",
        "    # Emission probabilities/matrix\n",
        "    sns.heatmap(emissions, annot=True, fmt=\".2f\", cmap='Blues',\n",
        "                xticklabels=emission_names, yticklabels=state_names, ax=axs[2], cbar=False)\n",
        "    axs[2].set_title('Emission Probabilities')\n",
        "    axs[2].set_xlabel('Donations in a Year')\n",
        "    axs[2].set_ylabel('Latent State')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def build_emission_matrix_truncated_poisson(rates, max_k=4):\n",
        "    S = len(rates)\n",
        "    K = max_k + 1   # da 0 a max_k incluso\n",
        "    emissions = np.zeros((S, K))\n",
        "    for s in range(S):\n",
        "        for k in range(max_k):\n",
        "            emissions[s, k] = poisson.pmf(k, rates[s])\n",
        "        # L'ultimo raccoglie la coda (tutto >= max_k)\n",
        "        emissions[s, max_k] = 1 - poisson.cdf(max_k-1, rates[s])\n",
        "    return emissions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "emissions_matrix = build_emission_matrix_truncated_poisson(rates, max_k=4)\n",
        "\n",
        "plot_hmm_params(\n",
        "    transitions=A_mean,\n",
        "    initial_probs=pi_mean,\n",
        "    emissions=emissions_matrix,\n",
        "    emission_names=[str(i) for i in range(4)] + [\"≥4\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diagnostics\n",
        "\n",
        "## Viterbi Algorithm\n",
        "\n",
        "Viterbi decoder\\\n",
        "Goal : for each donor find the MAP latent path $z_{0:T}^\\ast$.\n",
        "\n",
        "Plug-in parameters (posterior means)\\\n",
        "$$\\hat\\pi_k = \\frac{\\alpha_{\\pi,k}}{\\sum_{j}\\alpha_{\\pi,j}},\\qquad\n",
        "  \\hat A_{kj} = \\frac{\\alpha_{A_{k j}}}{\\sum_{j'}\\alpha_{A_{k j'}}},\\qquad\n",
        "  \\hat\\lambda_k = \\frac{\\alpha_k}{\\beta_k}.$$\n",
        "\n",
        "Dynamic programming\\\n",
        "Initial step\\\n",
        "$$\\delta_0(k)=\\log\\hat\\pi_k+\\log\\text{Poisson}(y_0\\mid\\hat\\lambda_k).$$\n",
        "\n",
        "Recursion for $t=1,\\dots,T$\\\n",
        "$$\\delta_t(j)=\\max_k\\bigl[\\delta_{t-1}(k)+\\log\\hat A_{k j}\\bigr]\n",
        "               +\\log\\text{Poisson}(y_t\\mid\\hat\\lambda_j),$$\\\n",
        "$$\\psi_t(j)=\\arg\\max_k\\bigl[\\delta_{t-1}(k)+\\log\\hat A_{k j}\\bigr].$$\n",
        "\n",
        "Back-tracking\\\n",
        "Start with $z_T^\\ast=\\arg\\max_k\\delta_T(k)$, then\\\n",
        "$z_{t-1}^\\ast=\\psi_t(z_t^\\ast)$ for $t=T,\\dots,1$.\n",
        "\n",
        "Cost $O(NTK^2)$ but vectorised in PyTorch, so only a loop on $t$.\\\n",
        "Output tensor paths\\[N,T\\] of integers 0…K-1, used for diagnostics and plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def viterbi_paths_poisson(obs,      # LongTensor [N,T]\n",
        "                          K=3):     # # latent states\n",
        "    \"\"\"\n",
        "    Returns the most-likely latent path for every individual\n",
        "    using the current variational parameters of the Poisson HMM.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # ----- expected model parameters ---------------------------------\n",
        "        # initial probs π\n",
        "        pi_alpha = pyro.param(\"pi_alpha\")                  # [K]\n",
        "        pi_prob  = pi_alpha / pi_alpha.sum()               # [K]\n",
        "        log_pi   = pi_prob.log()\n",
        "\n",
        "        # transition matrix A\n",
        "        A_alpha  = pyro.param(\"A_alpha\")                   # [K,K]\n",
        "        A_prob   = A_alpha / A_alpha.sum(1, keepdim=True)  # rows sum 1\n",
        "        log_A    = A_prob.log()\n",
        "\n",
        "        # Poisson rates λ\n",
        "        r_alpha  = pyro.param(\"r_alpha\")                   # [K]\n",
        "        r_beta   = pyro.param(\"r_beta\")\n",
        "        rates    = r_alpha / r_beta                       # [K]\n",
        "\n",
        "        # ----- pre-compute emission log-probs ----------------------------\n",
        "        N, T = obs.shape\n",
        "        emis_log = dist.Poisson(rates).log_prob(obs.unsqueeze(-1))  # (N,T,K)\n",
        "\n",
        "        # ----- Viterbi ----------------------------------------------------\n",
        "        paths  = torch.zeros(N, T, dtype=torch.long)\n",
        "        psi    = torch.zeros(N, T, K, dtype=torch.long)   # back-pointers\n",
        "        delta  = log_pi + emis_log[:, 0]                  # (N,K)\n",
        "\n",
        "        for t in range(1, T):\n",
        "            # score: delta_prev + log A (broadcast prev→next)\n",
        "            score = delta.unsqueeze(2) + log_A            # (N,K_prev,K_next)\n",
        "            delta, psi[:, t] = torch.max(score, dim=1)    # argmax over prev\n",
        "            delta += emis_log[:, t]                       # add emission\n",
        "\n",
        "        # back-tracking\n",
        "        last = torch.argmax(delta, dim=1)                 # (N,)\n",
        "        paths[:, -1] = last\n",
        "        for t in range(T - 1, 0, -1):\n",
        "            last = psi[torch.arange(N), t, last]\n",
        "            paths[:, t-1] = last\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "paths = viterbi_paths_poisson(obs_torch, K=3).cpu().numpy()\n",
        "\n",
        "# e.g. fraction of sequences that switch state at least once\n",
        "switch = (paths[:, 1:] != paths[:, :-1]).any(1).mean()\n",
        "print(f\"Sequences with ≥1 switch: {switch * 100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## State occupancy over time (population view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "counts = np.apply_along_axis(lambda col: np.bincount(col, minlength=3),\n",
        "                             0, paths)          # (K,T)\n",
        "props  = counts / counts.sum(0, keepdims=True)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "for k,c in enumerate(['tab:orange','tab:blue','tab:green']):\n",
        "    plt.plot(props[k], label=f'state {k}', color=c)\n",
        "plt.xlabel('year index'); plt.ylabel('population share')\n",
        "plt.title('State occupancy over time'); plt.legend(); plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rates with confidence bands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rate_sd   = np.sqrt(pyro.param(\"r_alpha\").detach().numpy()) / pyro.param(\"r_beta\").detach().numpy()\n",
        "ci = 1.96 * rate_sd\n",
        "plt.errorbar(np.arange(K), rates, yerr=ci, fmt='o')\n",
        "plt.xticks(range(K)); plt.ylabel('λ'); plt.title('Poisson rates with 95% CI')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network / chord diagram of transitions\n",
        "\n",
        "A visual alternative to the heat-map, highlights main flows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import networkx as nx\n",
        "G = nx.DiGraph()\n",
        "for i in range(K):\n",
        "    for j in range(K):\n",
        "        if A_mean[i,j] > 0.02:                 # ignore tiny flows\n",
        "            G.add_edge(i, j, weight=A_mean[i,j])\n",
        "pos = nx.circular_layout(G)\n",
        "weights = [G[u][v]['weight']*10 for u,v in G.edges]\n",
        "nx.draw(G, pos, with_labels=True, width=weights,\n",
        "        edge_color='grey', node_size=2000, cmap='viridis')\n",
        "plt.title('Transition network (edges >2%)'); plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual trajectories\n",
        "\n",
        "Pick a few donors and overlay observations + decoded state for an easy interpretation of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "from matplotlib.patches import Patch\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# globals\n",
        "# ------------------------------------------------------------\n",
        "K           = 3\n",
        "state_cols  = ['#e41a1c', '#377eb8', '#4daf4a']          # 3 colori Set1\n",
        "cmap        = ListedColormap(state_cols)\n",
        "norm        = BoundaryNorm(np.arange(-0.5, K+0.5, 1), cmap.N)\n",
        "years_axis  = np.arange(2009, 2024)                      # 2009 .. 2024\n",
        "yticks_vals = np.arange(0, 5)                            # 0 .. 4\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "def plot_one(idx):\n",
        "    x = obs_torch[idx].cpu().numpy()       # osservazioni (T,)\n",
        "    z = paths[idx]                         # stati latenti (T,)\n",
        "    T = len(x)\n",
        "    assert T == len(years_axis), \"years_axis length must match T\"\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.scatter(range(T), x, c=z, cmap=cmap, norm=norm, s=60, zorder=3)\n",
        "    plt.step(range(T), x, where='mid', color='k', alpha=.35, zorder=2)\n",
        "\n",
        "    # ---------- axis formatting ----------------------------------------\n",
        "    plt.xticks(ticks=range(T), labels=years_axis, rotation=45)\n",
        "    plt.yticks(ticks=yticks_vals)\n",
        "    plt.ylim(-0.5, 4.5)                     # blocca a 0–4\n",
        "    plt.grid(axis='y', linestyle=':', alpha=.4, zorder=1)\n",
        "\n",
        "    # ---------- legenda discreta ---------------------------------------\n",
        "    handles = [Patch(color=state_cols[k], label=f'State {k}') for k in range(K)]\n",
        "    plt.legend(handles=handles, title='latent state',\n",
        "               bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "    plt.title(f'Donor {idx}')\n",
        "    plt.xlabel('year')\n",
        "    plt.ylabel('# donations')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for i in [100, 1002, 3002]:\n",
        "    plot_one(i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\erik4\\AppData\\Local\\Programs\\Python\\Python313\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}